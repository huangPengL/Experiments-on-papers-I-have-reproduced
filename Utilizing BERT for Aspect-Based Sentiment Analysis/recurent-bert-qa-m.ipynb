{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-09-19T09:21:58.952681Z","iopub.execute_input":"2022-09-19T09:21:58.953083Z","iopub.status.idle":"2022-09-19T09:21:58.983762Z","shell.execute_reply.started":"2022-09-19T09:21:58.953001Z","shell.execute_reply":"2022-09-19T09:21:58.982731Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/bert-qa-m-for-absa/test_QA_M.tsv\n/kaggle/input/bert-qa-m-for-absa/dev_QA_M.tsv\n/kaggle/input/bert-qa-m-for-absa/train_QA_M.tsv\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install transformers","metadata":{"execution":{"iopub.status.busy":"2022-09-19T09:21:58.985813Z","iopub.execute_input":"2022-09-19T09:21:58.986462Z","iopub.status.idle":"2022-09-19T09:22:11.350401Z","shell.execute_reply.started":"2022-09-19T09:21:58.986426Z","shell.execute_reply":"2022-09-19T09:22:11.349245Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.20.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.7.1)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (21.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.28.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\nRequirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.12.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.12.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.8.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.3.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.8.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.12)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.3)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.6.15.2)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.1.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport random\nimport numpy as np\n\n# identify and specify the GPU as the device, later in training loop we will load data into device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nn_gpu = torch.cuda.device_count()\ntorch.cuda.get_device_name(0)\n\nSEED = 19\n\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\nif device == torch.device(\"cuda\"):\n    torch.cuda.manual_seed_all(SEED)\n\n    \nprint(device)","metadata":{"execution":{"iopub.status.busy":"2022-09-19T09:22:11.352607Z","iopub.execute_input":"2022-09-19T09:22:11.353367Z","iopub.status.idle":"2022-09-19T09:22:12.937847Z","shell.execute_reply.started":"2022-09-19T09:22:11.353323Z","shell.execute_reply":"2022-09-19T09:22:12.936880Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# loading and preprocessing data","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\ndf_train = pd.read_csv(\"/kaggle/input/bert-qa-m-for-absa/train_QA_M.tsv\",skiprows=1, delimiter='\\t', header = None, names=['id','sentence1','sentence2','label'])\ndf_test = pd.read_csv(\"/kaggle/input/bert-qa-m-for-absa/test_QA_M.tsv\",skiprows=1, delimiter='\\t', header = None,names=['id','sentence1','sentence2','label'])\ndf_val = pd.read_csv(\"/kaggle/input/bert-qa-m-for-absa/dev_QA_M.tsv\",skiprows=1, delimiter='\\t', header = None,names=['id','sentence1','sentence2','label'])\n\nprint(f\"train data len: {len(df_train)}\")\nprint(f\"test data len: {len(df_test)}\")\nprint(f\"val data len: {len(df_val)}\")","metadata":{"execution":{"iopub.status.busy":"2022-09-19T09:22:12.940368Z","iopub.execute_input":"2022-09-19T09:22:12.942716Z","iopub.status.idle":"2022-09-19T09:22:13.050414Z","shell.execute_reply.started":"2022-09-19T09:22:12.942666Z","shell.execute_reply":"2022-09-19T09:22:13.049104Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"train data len: 15008\ntest data len: 7516\nval data len: 3748\n","output_type":"stream"}]},{"cell_type":"code","source":"print(df_train[:10])\n\nprint(\"\\n\")\nprint(df_train['label'].unique())\n\nunique_labels = df_train['label'].unique()","metadata":{"execution":{"iopub.status.busy":"2022-09-19T09:22:13.051974Z","iopub.execute_input":"2022-09-19T09:22:13.052343Z","iopub.status.idle":"2022-09-19T09:22:13.070707Z","shell.execute_reply.started":"2022-09-19T09:22:13.052306Z","shell.execute_reply":"2022-09-19T09:22:13.069728Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"     id                                          sentence1  \\\n0     0                        location - 2 , location - 1   \n1     0                        location - 2 , location - 1   \n2     0                        location - 2 , location - 1   \n3     0                        location - 2 , location - 1   \n4  1000  location - 1 is one of the most expensive area...   \n5  1000  location - 1 is one of the most expensive area...   \n6  1000  location - 1 is one of the most expensive area...   \n7  1000  location - 1 is one of the most expensive area...   \n8  1001  the hard rock cafe is close by , just by locat...   \n9  1001  the hard rock cafe is close by , just by locat...   \n\n                                           sentence2     label  \n0  what do you think of the general of location -...      None  \n1   what do you think of the price of location - 1 ?      None  \n2  what do you think of the safety of location - 1 ?      None  \n3  what do you think of the transit location of l...      None  \n4  what do you think of the general of location -...      None  \n5   what do you think of the price of location - 1 ?  Negative  \n6  what do you think of the safety of location - 1 ?      None  \n7  what do you think of the transit location of l...      None  \n8  what do you think of the general of location -...      None  \n9   what do you think of the price of location - 1 ?      None  \n\n\n['None' 'Negative' 'Positive']\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\n# 将字符串映射成整型\ndef train_str_2_int(df):\n    labelEncoder = LabelEncoder()\n    df['label_enc'] = labelEncoder.fit_transform(df['label'])\n    \n    # 原地给列改名\n    df.rename(columns = {'label': 'label_desc'}, inplace = True)\n    df.rename(columns = {'label_enc': 'label'}, inplace = True)\n\n    \ntrain_str_2_int(df_train)\ntrain_str_2_int(df_test)\ntrain_str_2_int(df_val)","metadata":{"execution":{"iopub.status.busy":"2022-09-19T09:22:13.073027Z","iopub.execute_input":"2022-09-19T09:22:13.074055Z","iopub.status.idle":"2022-09-19T09:22:13.424628Z","shell.execute_reply.started":"2022-09-19T09:22:13.074019Z","shell.execute_reply":"2022-09-19T09:22:13.423613Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"print(df_train[0:10])\nprint(df_test[0:10])\nprint(df_val[0:10])","metadata":{"execution":{"iopub.status.busy":"2022-09-19T09:22:13.426158Z","iopub.execute_input":"2022-09-19T09:22:13.426536Z","iopub.status.idle":"2022-09-19T09:22:13.442261Z","shell.execute_reply.started":"2022-09-19T09:22:13.426500Z","shell.execute_reply":"2022-09-19T09:22:13.441235Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"     id                                          sentence1  \\\n0     0                        location - 2 , location - 1   \n1     0                        location - 2 , location - 1   \n2     0                        location - 2 , location - 1   \n3     0                        location - 2 , location - 1   \n4  1000  location - 1 is one of the most expensive area...   \n5  1000  location - 1 is one of the most expensive area...   \n6  1000  location - 1 is one of the most expensive area...   \n7  1000  location - 1 is one of the most expensive area...   \n8  1001  the hard rock cafe is close by , just by locat...   \n9  1001  the hard rock cafe is close by , just by locat...   \n\n                                           sentence2 label_desc  label  \n0  what do you think of the general of location -...       None      1  \n1   what do you think of the price of location - 1 ?       None      1  \n2  what do you think of the safety of location - 1 ?       None      1  \n3  what do you think of the transit location of l...       None      1  \n4  what do you think of the general of location -...       None      1  \n5   what do you think of the price of location - 1 ?   Negative      0  \n6  what do you think of the safety of location - 1 ?       None      1  \n7  what do you think of the transit location of l...       None      1  \n8  what do you think of the general of location -...       None      1  \n9   what do you think of the price of location - 1 ?       None      1  \n     id                                          sentence1  \\\n0     0  if you want to go out drinking where the cool ...   \n1     0  if you want to go out drinking where the cool ...   \n2     0  if you want to go out drinking where the cool ...   \n3     0  if you want to go out drinking where the cool ...   \n4  1000  location - 1 actually has quite a cool feel to...   \n5  1000  location - 1 actually has quite a cool feel to...   \n6  1000  location - 1 actually has quite a cool feel to...   \n7  1000  location - 1 actually has quite a cool feel to...   \n8  1001  there ' s location - 1 , which is , i would sa...   \n9  1001  there ' s location - 1 , which is , i would sa...   \n\n                                           sentence2 label_desc  label  \n0  what do you think of the general of location -...       None      1  \n1   what do you think of the price of location - 1 ?       None      1  \n2  what do you think of the safety of location - 1 ?       None      1  \n3  what do you think of the transit location of l...       None      1  \n4  what do you think of the general of location -...   Positive      2  \n5   what do you think of the price of location - 1 ?       None      1  \n6  what do you think of the safety of location - 1 ?       None      1  \n7  what do you think of the transit location of l...       None      1  \n8  what do you think of the general of location -...       None      1  \n9   what do you think of the price of location - 1 ?       None      1  \n    id                                          sentence1  \\\n0    0        i stayed in location - 1 and loved the area   \n1    0        i stayed in location - 1 and loved the area   \n2    0        i stayed in location - 1 and loved the area   \n3    0        i stayed in location - 1 and loved the area   \n4  100  personally , i do n't think location - 1 is th...   \n5  100  personally , i do n't think location - 1 is th...   \n6  100  personally , i do n't think location - 1 is th...   \n7  100  personally , i do n't think location - 1 is th...   \n8  101  in london outskirts ( south of london ) there ...   \n9  101  in london outskirts ( south of london ) there ...   \n\n                                           sentence2 label_desc  label  \n0  what do you think of the general of location -...   Positive      2  \n1   what do you think of the price of location - 1 ?       None      1  \n2  what do you think of the safety of location - 1 ?       None      1  \n3  what do you think of the transit location of l...       None      1  \n4  what do you think of the general of location -...   Positive      2  \n5   what do you think of the price of location - 1 ?       None      1  \n6  what do you think of the safety of location - 1 ?       None      1  \n7  what do you think of the transit location of l...       None      1  \n8  what do you think of the general of location -...       None      1  \n9   what do you think of the price of location - 1 ?   Positive      2  \n","output_type":"stream"}]},{"cell_type":"markdown","source":"# encode sentence ","metadata":{}},{"cell_type":"code","source":"from transformers import BertTokenizer\n\nmodel_ckpt = 'bert-base-uncased'\ntokenizer = BertTokenizer.from_pretrained(model_ckpt, do_lower_case=True)\n\ndef tokenizing(df, tokenizer, MAX_LEN = 256):\n\n    sent1 = df.sentence1.values\n    sent2 = df.sentence2.values\n    sentences = [sent1[i] + \"[SEP]\" + sent2[i] for i in range(len(sent1))]\n    labels = df.label.values\n\n    input_ids = [tokenizer.encode(sent,add_special_tokens=True,max_length=MAX_LEN,pad_to_max_length=True) for sent in sentences]\n    attention_masks = [[float(i>0) for i in input_id]for input_id in input_ids]\n    \n    return input_ids, attention_masks, labels\n\n\ntrain_input_ids, train_attention_masks, train_labels = tokenizing(df_train, tokenizer)\ntest_input_ids, test_attention_masks, test_labels = tokenizing(df_test, tokenizer)\nval_input_ids, val_attention_masks, val_labels = tokenizing(df_val, tokenizer)\n\nprint(f\"train data len: {len(train_input_ids)}\")\nprint(f\"test data len: {len(test_input_ids)}\")\nprint(f\"val data len: {len(val_input_ids)}\")","metadata":{"execution":{"iopub.status.busy":"2022-09-19T09:22:13.443889Z","iopub.execute_input":"2022-09-19T09:22:13.444555Z","iopub.status.idle":"2022-09-19T09:22:42.175819Z","shell.execute_reply.started":"2022-09-19T09:22:13.444418Z","shell.execute_reply":"2022-09-19T09:22:42.174758Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7fb6aaf067f44239834a4313b7b492a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc9b3c4d59cf453290cc3a3e54d3869a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"616046938ad846b08d29da70d494fdc7"}},"metadata":{}},{"name":"stderr","text":"Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  FutureWarning,\n","output_type":"stream"},{"name":"stdout","text":"train data len: 15008\ntest data len: 7516\nval data len: 3748\n","output_type":"stream"}]},{"cell_type":"code","source":"print(train_input_ids[0])\nprint(train_attention_masks[0])\nprint(train_labels[0])\nprint(tokenizer.convert_ids_to_tokens(train_input_ids[0]))","metadata":{"execution":{"iopub.status.busy":"2022-09-19T09:22:42.178252Z","iopub.execute_input":"2022-09-19T09:22:42.178955Z","iopub.status.idle":"2022-09-19T09:22:42.186545Z","shell.execute_reply.started":"2022-09-19T09:22:42.178912Z","shell.execute_reply":"2022-09-19T09:22:42.185220Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"[101, 3295, 1011, 1016, 1010, 3295, 1011, 1015, 102, 2054, 2079, 2017, 2228, 1997, 1996, 2236, 1997, 3295, 1011, 1015, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n1\n['[CLS]', 'location', '-', '2', ',', 'location', '-', '1', '[SEP]', 'what', 'do', 'you', 'think', 'of', 'the', 'general', 'of', 'location', '-', '1', '?', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n\n# convert all our data into torch tensors, required data type for our model\ntrain_input_ids = torch.tensor(train_input_ids)\ntrain_attention_masks = torch.tensor(train_attention_masks)\ntrain_labels = torch.tensor(train_labels)\n\ntest_input_ids = torch.tensor(test_input_ids)\ntest_attention_masks = torch.tensor(test_attention_masks)\ntest_labels = torch.tensor(test_labels)\n\nval_input_ids = torch.tensor(val_input_ids)\nval_attention_masks = torch.tensor(val_attention_masks)\nval_labels = torch.tensor(val_labels)\n\n# Select a batch size for training. For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32\nbatch_size = 32\n\n# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n# with an iterator the entire dataset does not need to be loaded into memory\ntrain_data = TensorDataset(train_input_ids,train_attention_masks,train_labels)\ntrain_sampler = RandomSampler(train_data)\ntrain_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n\ntest_data = TensorDataset(test_input_ids,test_attention_masks,test_labels)\ntest_sampler = RandomSampler(test_data)\ntest_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n\nval_data = TensorDataset(val_input_ids,val_attention_masks,val_labels)\nval_sampler = RandomSampler(val_data)\nval_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-09-19T09:22:42.190262Z","iopub.execute_input":"2022-09-19T09:22:42.190932Z","iopub.status.idle":"2022-09-19T09:22:42.885837Z","shell.execute_reply.started":"2022-09-19T09:22:42.190888Z","shell.execute_reply":"2022-09-19T09:22:42.884876Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"print(len(train_dataloader))\nprint(len(test_dataloader))\nprint(len(val_dataloader))","metadata":{"execution":{"iopub.status.busy":"2022-09-19T09:22:42.887236Z","iopub.execute_input":"2022-09-19T09:22:42.887601Z","iopub.status.idle":"2022-09-19T09:22:42.894503Z","shell.execute_reply.started":"2022-09-19T09:22:42.887559Z","shell.execute_reply":"2022-09-19T09:22:42.893248Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"469\n235\n118\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# define Model, Hyperparameter, optimizer","metadata":{}},{"cell_type":"code","source":"from transformers import BertConfig,AdamW, BertForSequenceClassification,get_linear_schedule_with_warmup\n\n\n\nmodel = BertForSequenceClassification.from_pretrained(model_ckpt, num_labels=len(unique_labels)).to(device)\n\nlr = 2e-5\nadam_epsilon = 1e-8\nepochs = 3\n\nnum_warmup_steps = 0\nnum_training_steps = len(train_dataloader) * epochs\n\noptimizer = AdamW(model.parameters(), lr = lr, eps = adam_epsilon, correct_bias = False)\nscheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = num_warmup_steps, num_training_steps = num_training_steps)\n","metadata":{"execution":{"iopub.status.busy":"2022-09-19T09:22:42.896029Z","iopub.execute_input":"2022-09-19T09:22:42.896370Z","iopub.status.idle":"2022-09-19T09:23:03.978533Z","shell.execute_reply.started":"2022-09-19T09:22:42.896334Z","shell.execute_reply":"2022-09-19T09:23:03.977258Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b365df29652841098be08262b8a6e619"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']\n- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# train model and test","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm, trange,notebook,tqdm_notebook\nimport time\n\nfrom sklearn.metrics import confusion_matrix,classification_report\n# Import and evaluate each test batch using Matthew's correlation coefficient\nfrom sklearn.metrics import accuracy_score,matthews_corrcoef\n\nmodel.zero_grad()\n\n# 用作画图\ntrain_loss_list = []\n\n# 查看训练过程中的learning rate 变化\nlearning_rate = []\n\nfor epoch in notebook.tnrange(1, epochs+1, desc = 'Epoch'):\n    start = time.time()\n    print(\"<\" + \"=\"*22 + f\"Epoch{epoch}, Batch{len(train_dataloader)}\" + \"=\"*22 + \">\")\n    \n    all_loss = 0\n    \n    curSample = 0.0\n    curRight = 0\n    \n    # 开始训练\n    for step, batch in enumerate(train_dataloader):\n        \n        model.train()\n        \n        # 放入gpu中\n        batch = tuple(t.to(device) for t in batch)\n        \n        b_input_ids, b_input_mask, b_labels = batch\n        \n        # tips: BertForSequenceClassifier 输出的第一个是loss,第二个是（batchsize, label_prob）\n        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels = b_labels)\n        loss = outputs[0]\n        label_prob = outputs[1]\n        \n        label_prob = label_prob.to('cpu').detach().numpy()\n        label_prob = np.argmax(label_prob, axis=1).flatten()\n        b_labels = b_labels.to('cpu').detach().numpy().flatten()\n        curSample += len(b_labels)\n        curRight += (label_prob == b_labels).sum().item()\n        \n        loss.backward()\n        \n        optimizer.step()\n        \n        scheduler.step()\n        \n        optimizer.zero_grad()\n        \n        all_loss += loss.item()\n        \n        \n        if (step+1) % 50 == 0:\n            print(f\"step: {step+1} loss:{all_loss / (step+1)} time: {time.time() - start} cur acc:{curRight / curSample}\")\n    \n\n    #store the current learning rate\n    for param_group in optimizer.param_groups:\n        print(\"\\n\\tCurrent Learning rate: \",param_group['lr'])\n        learning_rate.append(param_group['lr'])\n\n        \n    train_loss_list.append(all_loss / len(train_dataloader))\n    print(F'\\n\\tAverage Training loss: {train_loss_list[-1]}')\n    \n    \n    # ================= Validation or Test ================== #\n    def testOrVal(dataloader, mode='test'):\n        model.eval()\n\n        eval_acc, eval_mcc, nb_eval_steps = 0, 0, 0\n\n        for batch in dataloader:\n            batch = tuple(t.to(device) for t in batch)\n\n            b_input_ids, b_input_mask, b_labels = batch\n\n            with torch.no_grad():\n                outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n\n            pred = outputs[0].to('cpu').numpy()\n            true_label = b_labels.to('cpu').numpy()\n\n            pred_flat = np.argmax(pred, axis=1).flatten()\n            labels_flat = true_label.flatten()\n\n            tmp_eval_accuracy = accuracy_score(labels_flat,pred_flat)\n            tmp_eval_mcc_accuracy = matthews_corrcoef(labels_flat, pred_flat)\n\n            eval_acc += tmp_eval_accuracy\n            eval_mcc += tmp_eval_mcc_accuracy\n            nb_eval_steps += 1\n        if mode == 'val':\n            print(F'\\n\\tValidation Accuracy: {eval_acc/nb_eval_steps}')\n            print(F'\\n\\tValidation MCC Accuracy: {eval_mcc/nb_eval_steps}')\n        else:\n            print(F'\\n\\tTest Accuracy: {eval_acc/nb_eval_steps}')\n            print(F'\\n\\tTest MCC Accuracy: {eval_mcc/nb_eval_steps}')\n    \n    testOrVal(val_dataloader, \"val\")\n    testOrVal(test_dataloader, \"test\")","metadata":{"execution":{"iopub.status.busy":"2022-09-19T09:23:03.980703Z","iopub.execute_input":"2022-09-19T09:23:03.981169Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Epoch:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7a2d5be718b4a1cafc1e75db6fb547b"}},"metadata":{}},{"name":"stdout","text":"<======================Epoch1, Batch469======================>\nstep: 50 loss:0.5660203444957733 time: 37.501582860946655 cur acc:0.825\nstep: 100 loss:0.5438286039233208 time: 73.90973949432373 cur acc:0.831875\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}